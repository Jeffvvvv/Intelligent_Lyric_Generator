{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jz2av\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "from string import punctuation\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F \n",
    "import torch.utils.data\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "\n",
    "from keyword_extraction import RakeKeywordExtractor\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rake = RakeKeywordExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.33333333333333\n",
      "Because we all get caught up in all the drama\n",
      "[('caught', 32.33333333333333)]\n",
      "['caught', 'drama']\n"
     ]
    }
   ],
   "source": [
    "# test of sentence extraction\n",
    "string = \"Because we all get caught up in all the drama\"\n",
    "keywords = rake.sen_extract(string, incl_scores = True, word_num=1) # incl_scores: display the score, word_num: number of keywords\n",
    "print(keywords[0][1])\n",
    "\n",
    "def SigKeywordExtract(sentence):\n",
    "    keywords = rake.sen_extract(sentence, incl_scores = True, word_num=1)\n",
    "    if not keywords:\n",
    "        return None;\n",
    "    else:\n",
    "        return keywords\n",
    "\n",
    "def MutiKeywordExtract(sentence, num):\n",
    "    keywords = rake.sen_extract(sentence, incl_scores = True, word_num=num)\n",
    "    res = []\n",
    "    for keyword in keywords:\n",
    "        res.append(keyword[0])\n",
    "    return res\n",
    "print(string)\n",
    "print(SigKeywordExtract(string))\n",
    "print(MutiKeywordExtract(string, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly\n",
    "We define a class to build corpus which contains wordEmbedding function (word2Index and Index2word).\n",
    "In the class, we provide a function to calculate the number of tokens in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class lang: Convert each word to index and convert each index to word\n",
    "# WordEmbedding - this structure can be viewed as a corpus \n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2 #count SOS and EOS\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        if sentence:\n",
    "             for word in sentence.split(' '):\n",
    "                self.addWord(word)\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly\n",
    "We process the training text data, load the data, convert the csv file into list[pair]. \n",
    "For every pair in the list, pair[0] is the current sentence(Encoder input), pair[1] is the next sentence(ground truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepare for training data\n",
    "#Convert all Unicode to ASCII, normalize the word: make everything lowercase, trim most punctuations\n",
    "# def unicodeToAscii(s):\n",
    "#     return ''.join(\n",
    "#         c for c in unicodedata.normalize('NFD', s)\n",
    "#         if unicodedata.category(c) != 'Mn'\n",
    "#     )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = ''.join(c for c in s if c not in punctuation)\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "#Load data, process data into pairs(pair[0] is current sentence, pair[1] is the next sentence)\n",
    "#Pair[0] is the input sentence, pair[1] is the ground truth\n",
    "def loadData():\n",
    "    pf = open('pop_eng_clean.csv', 'r')\n",
    "    df = pd.read_csv(pf, delimiter=',', names=['index', 'remix', 'yead', 'singer', 'type', 'lyric','keywords','scores'])\n",
    "    lyrics = df['lyric'].tolist()\n",
    "    keywords = df['keywords'].tolist()\n",
    "    scores = df['scores'].tolist()\n",
    "    print(len(keywords))\n",
    "    \n",
    "    pairs = []\n",
    "    cnt = 0\n",
    "    songs_len = len(lyrics)\n",
    "    total_line = 0\n",
    "    for i in range(1, len(lyrics)):\n",
    "        if(i%1000==0): print(i)\n",
    "#     for i in range(1, 1000):\n",
    "        lyrics_lines = lyrics[i].split('\\n')\n",
    "        keywords_lines = keywords[i].split('\\n')\n",
    "        scores_lines = scores[i].split('\\n')\n",
    "        lyric_line_num = len(lyrics_lines)\n",
    "#         keywords_line_num = len(keywords_lines)\n",
    "#         in each song\n",
    "        isFirstLine = True\n",
    "#     sometimes in the dataset there are 49 lines of lyrics, only 1 keywords\n",
    "        if(len(keywords_lines)<len(lyrics_lines)): continue\n",
    "#         print(len(lyrics_lines), len(keywords_lines))\n",
    "        for j in range(lyric_line_num):\n",
    "            total_line+=1\n",
    "            pair = []\n",
    "            current_lyric = lyrics_lines[j]\n",
    "            current_keyword = keywords_lines[j]\n",
    "            current_score = scores_lines[j]\n",
    "            if(len(current_score)>0 and round(float(current_score))>20):\n",
    "                if(isFirstLine):\n",
    "                    pair.append(normalizeString(current_keyword))\n",
    "                    isFirstLine = False\n",
    "                else:\n",
    "                    pair.append(normalizeString(current_keyword+' '+previous_lyric))\n",
    "                pair.append(normalizeString(current_lyric))\n",
    "                pairs.append(pair)\n",
    "            previous_lyric = current_lyric\n",
    "    print(total_line)\n",
    "    print(len(pairs))\n",
    "    return pairs\n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "#     for d in lyric:\n",
    "#         if(cnt==0):break\n",
    "#         cnt+=1\n",
    "#         lines = d.decode('utf-8').split('\\n')\n",
    "#         #Process the first pair [keyword + null]\n",
    "#         first_keyword = SigKeywordExtract(lines[0])\n",
    "#         if first_keyword:\n",
    "#             pair = [first_keyword[0][0].encode('utf-8'), lines[0].encode('utf-8')]\n",
    "#         i = 0\n",
    "#         j = 1\n",
    "#         pairs.append(pair)\n",
    "\n",
    "#         while j<len(lines):\n",
    "#             pair = []\n",
    "#             next_keyword = SigKeywordExtract(lines[j])\n",
    "#             if next_keyword:\n",
    "#                 if(next_keyword[0][1]>40):\n",
    "#                     newline = next_keyword[0][0] + ' ' + normalizeString(lines[i])\n",
    "#                     pair.append(normalizeString(newline).encode('utf-8'))\n",
    "#                     pair.append(normalizeString(lines[j]).encode('utf-8'))\n",
    "#                     pairs.append(pair)\n",
    "#             i += 1\n",
    "#             j += 1\n",
    "#         break\n",
    "#     return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28806\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "1156621\n",
      "797532\n",
      "Read 797532 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "lyric 96593\n"
     ]
    }
   ],
   "source": [
    "#Define a prepareData function to process all the input sentence pairs\n",
    "def prepareData(lang):\n",
    "    pairs = loadData()\n",
    "    lang = Lang(lang)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        if pair: \n",
    "            lang.addSentence(pair[0])\n",
    "            lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(lang.name, lang.n_words)\n",
    "    return lang, pairs\n",
    "\n",
    "\n",
    "lang, pairs = prepareData('lyric')\n",
    "#randomly choose a pair, print pair[0] and pair[1]\n",
    "i = 0\n",
    "# while i<100:\n",
    "#     print(random.choice(pairs))\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_pairs = pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Encoder and Decoder\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Encoder and Decoder\n",
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output.view(len(input), 1, -1), hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(1, 1, self.hidden_size, device=device))\n",
    "    \n",
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output.view(len(input), 1, -1), hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(1, 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "#Prepare for training data\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(input_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to plot the figure\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "#define epoch for training and print the result periodically \n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(selected_pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 1s (- 100m 51s) (1000 1%) 7.5366\n",
      "1m 48s (- 88m 44s) (2000 2%) 6.7303\n",
      "2m 35s (- 83m 49s) (3000 3%) 6.4894\n",
      "3m 24s (- 81m 41s) (4000 4%) 6.2938\n",
      "4m 13s (- 80m 24s) (5000 5%) 6.1339\n",
      "5m 2s (- 78m 53s) (6000 6%) 6.2620\n",
      "5m 50s (- 77m 43s) (7000 7%) 5.9556\n",
      "6m 40s (- 76m 46s) (8000 8%) 6.0603\n",
      "7m 28s (- 75m 34s) (9000 9%) 6.0251\n",
      "8m 17s (- 74m 37s) (10000 10%) 5.9799\n",
      "9m 6s (- 73m 39s) (11000 11%) 5.9551\n",
      "9m 55s (- 72m 45s) (12000 12%) 5.8077\n",
      "10m 44s (- 71m 52s) (13000 13%) 5.8317\n",
      "11m 31s (- 70m 49s) (14000 14%) 5.8142\n",
      "12m 19s (- 69m 52s) (15000 15%) 5.7716\n",
      "13m 8s (- 69m 1s) (16000 16%) 5.8118\n",
      "13m 57s (- 68m 10s) (17000 17%) 5.7200\n",
      "14m 45s (- 67m 13s) (18000 18%) 5.7098\n",
      "15m 33s (- 66m 20s) (19000 19%) 5.7472\n",
      "16m 21s (- 65m 25s) (20000 20%) 5.7608\n",
      "17m 11s (- 64m 42s) (21000 21%) 5.7077\n",
      "18m 29s (- 65m 33s) (22000 22%) 5.6598\n",
      "20m 0s (- 67m 0s) (23000 23%) 5.6188\n",
      "21m 34s (- 68m 17s) (24000 24%) 5.6622\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-d9993740d259>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdecoder2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecoderLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainIters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoder2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-3bb77fb04414>\u001b[0m in \u001b[0;36mtrainIters\u001b[1;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[1;32m---> 38\u001b[1;33m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-63dac39fa896>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mei\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         encoder_output, encoder_hidden = encoder(\n\u001b[1;32m---> 18\u001b[1;33m             input_tensor[ei], encoder_hidden)\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mei\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-ea5f152aec6f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hidden)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0membedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "cell_size = 256\n",
    "encoder1 = EncoderRNN(lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, lang.n_words).to(device)\n",
    "\n",
    "encoder2 = EncoderLSTM(lang.n_words, hidden_size).to(device)\n",
    "decoder2 = DecoderLSTM(hidden_size, lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder2, decoder2, 100000, print_every=1000, learning_rate=0.1)\n",
    "torch.save(encoder2.state_dict(), \"encoder2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(decoder2.state_dict(), \"decoder2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder2 = EncoderLSTM(lang.n_words, hidden_size, cell_size).to(device)\n",
    "decoder2 = DecoderLSTM(hidden_size, cell_size, lang.n_words).to(device)\n",
    "\n",
    "encoder2.load_state_dict(torch.load(\"./encoder2\"))\n",
    "decoder2.load_state_dict(torch.load(\"./decoder2\"))\n",
    "\n",
    "trainIters(encoder2, decoder2,5000, print_every=1000, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainIters(encoder2, decoder2,20000, print_every=1000, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainIters(encoder2, decoder2,10000, print_every=1000, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder2 = EncoderLSTM(lang.n_words, hidden_size, cell_size).to(device)\n",
    "decoder2 = DecoderLSTM(hidden_size, cell_size, lang.n_words).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder2.load_state_dict(torch.load('encoder2'))\n",
    "decoder2.load_state_dict(torch.load('decoder2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#temporary function\n",
    "def evaluate(encoder, decoder, sentence, max_length=10):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(input_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "       # decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            #decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial keywords: ['happi', 'day', 'gon']\n",
      "Filtered keywords: ['happi', 'day', 'gon']\n"
     ]
    }
   ],
   "source": [
    "# input_sen = \"i am gonna be happy one day <EOS>\"\n",
    "input_sen = \"i am gonna be happy one day\"\n",
    "output_num = 3\n",
    "keywords = list(rake.sen_extract(input_sen, word_num=output_num))\n",
    "print (\"Initial keywords: \" + str(keywords))\n",
    "\n",
    "for keyword in keywords:\n",
    "    try:\n",
    "        lang.word2index[keyword]\n",
    "    except KeyError:\n",
    "        keywords.remove(keyword)\n",
    "        \n",
    "print (\"Filtered keywords: \" + str(keywords))\n",
    "output_num = len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromWord(lang, word):\n",
    "    return [lang.word2index[word.encode('utf-8')]]\n",
    "\n",
    "def tensorFromWord(lang, sentence):\n",
    "    indexes = indexesFromWord(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_word(encoder, decoder, sentence, max_length=10):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromWord(lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(input_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "       # decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            #decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence: ['cemetri', 'lohk', 'concentrating', 'crafti', 'bongo', 'breads', 'eastsid', 'Aimin', 'Jealousies', 'keojyeo']\n",
      "Final result: [['cemetri', 'lohk', 'concentrating', 'crafti', 'bongo', 'breads', 'eastsid', 'Aimin', 'Jealousies', 'keojyeo'], ['Tabitha', 'musiques', 'inneun', 'inneun', 'mournin', 'mennar', 'poin', 'geotman', 'Butmost', 'change'], ['lohk', 'concentrating', 'crafti', 'bongo', 'glint', 'mennar', 'Muffys', 'mennar', 'silvergirl', 'Etta']]\n"
     ]
    }
   ],
   "source": [
    "output_words = []\n",
    "input_sen = normalizeString(input_sen)\n",
    "new_input = keywords[0] + \" \" + input_sen\n",
    "output_word = evaluate(encoder1, decoder1, new_input)\n",
    "print (\"First sentence: \" + str(output_word))\n",
    "output_words.append(output_word)\n",
    "for i in range(1, output_num):\n",
    "    new_sen = keywords[i] + ' ' + ' '.join(output_word)\n",
    "    sen = ' '.join(new_sen.split(' ')[:-1])\n",
    "    output_word = evaluate(encoder1, decoder1, sen)\n",
    "    output_words.append(output_word)\n",
    "\n",
    "    \n",
    "print (\"Final result: \" + str(output_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
